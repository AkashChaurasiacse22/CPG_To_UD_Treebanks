{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYN98XApStzY",
        "outputId": "9141549c-e811-4668-af6e-9f2a8f75f096"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Exact matching complete. 9993 sentence(s) matched.\n",
            "ðŸ“„ Output written to /content/drive/MyDrive/Training_Data_BTP/parallel_data_exact_match1.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# === Recursively get all CPG files in a directory ===\n",
        "def get_cpg_files_from_directory(root_dir):\n",
        "    cpg_files = []\n",
        "    for root, _, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            cpg_files.append(os.path.join(root, file))\n",
        "    return cpg_files\n",
        "\n",
        "# === Extract sentences from CPG files ===\n",
        "def extract_cpg_sentences(cpg_paths):\n",
        "    all_sentences = []\n",
        "    for cpg_path in cpg_paths:\n",
        "        sentences = []\n",
        "        sentence_tokens = []\n",
        "        inside_sentence = False\n",
        "\n",
        "        with open(cpg_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if line.startswith(\"<Sentence id=\"):\n",
        "                    inside_sentence = True\n",
        "                    sentence_tokens = []\n",
        "                elif line.startswith(\"</Sentence>\"):\n",
        "                    if sentence_tokens:\n",
        "                        clean_tokens = [w for w in sentence_tokens if w not in {'(', ')', '((', '))'}]\n",
        "                        full_sentence = ' '.join(clean_tokens)\n",
        "                        sentences.append(full_sentence)\n",
        "                    inside_sentence = False\n",
        "                    sentence_tokens = []\n",
        "                elif inside_sentence and line and not line.startswith(\"<\"):\n",
        "                    parts = line.split('\\t')\n",
        "                    if len(parts) > 1:\n",
        "                        token = parts[1]\n",
        "                        if token not in {'(', ')', '((', '))'}:\n",
        "                            sentence_tokens.append(token)\n",
        "\n",
        "        all_sentences.extend(sentences)\n",
        "    return all_sentences\n",
        "\n",
        "# === Parse CPG sentence blocks ===\n",
        "def parse_cpg_blocks(cpg_files):\n",
        "    all_blocks = []\n",
        "    for cpg_path in cpg_files:\n",
        "        blocks = []\n",
        "        with open(cpg_path, 'r', encoding='utf-8') as f:\n",
        "            block = []\n",
        "            for line in f:\n",
        "                if \"<Sentence id=\" in line:\n",
        "                    block = [line.strip()]\n",
        "                elif \"</Sentence>\" in line:\n",
        "                    block.append(line.strip())\n",
        "                    blocks.append(block)\n",
        "                elif block:\n",
        "                    block.append(line.strip())\n",
        "        all_blocks.extend(blocks)\n",
        "    return all_blocks\n",
        "\n",
        "# === Parse UD blocks from .conllu files ===\n",
        "def parse_ud_blocks(ud_paths):\n",
        "    all_blocks = []\n",
        "    for ud_path in ud_paths:\n",
        "        with open(ud_path, 'r', encoding='utf-8') as f:\n",
        "            blocks = []\n",
        "            block = []\n",
        "            sentence_text = \"\"\n",
        "            for line in f:\n",
        "                if line.startswith(\"# text =\"):\n",
        "                    sentence_text = line.strip().replace(\"# text = \", \"\")\n",
        "                    block = [line.strip()]\n",
        "                elif line.strip() == \"\":\n",
        "                    if block:\n",
        "                        blocks.append((sentence_text, block))\n",
        "                        block = []\n",
        "                else:\n",
        "                    block.append(line.strip())\n",
        "            if block:\n",
        "                blocks.append((sentence_text, block))\n",
        "        all_blocks.extend(blocks)\n",
        "    return all_blocks\n",
        "\n",
        "# === Align sentences using exact matching and output ===\n",
        "def align_and_output_exact(sentences, cpg_blocks, ud_blocks, output_path):\n",
        "    ud_sentence_map = {s.strip().lower(): (s, b) for s, b in ud_blocks}\n",
        "\n",
        "    with open(output_path, 'w', encoding='utf-8') as out:\n",
        "        match_count = 0\n",
        "        for idx, sentence in enumerate(sentences):\n",
        "            norm_sentence = sentence.strip().lower()\n",
        "            if norm_sentence in ud_sentence_map:\n",
        "                matched_sentence, ud_block = ud_sentence_map[norm_sentence]\n",
        "                cpg_block = cpg_blocks[idx] if idx < len(cpg_blocks) else []\n",
        "\n",
        "                out.write(f\"### Sentence ID: {idx + 1}\\n\")\n",
        "                out.write(f\"# text = {sentence}\\n\")\n",
        "                out.write(f\"# Matched UD: {matched_sentence} (Exact Match)\\n\")\n",
        "                out.write(\"==UD==\\n\")\n",
        "                for line in ud_block:\n",
        "                    out.write(line + \"\\n\")\n",
        "                out.write(\"==CPG==\\n\")\n",
        "                for line in cpg_block:\n",
        "                    out.write(line + \"\\n\")\n",
        "                out.write(\"-------------------------------------------------------\\n\")\n",
        "                match_count += 1\n",
        "\n",
        "    print(f\"âœ… Exact matching complete. {match_count} sentence(s) matched.\")\n",
        "    print(f\"ðŸ“„ Output written to {output_path}\")\n",
        "\n",
        "# === Main Execution ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Root directory for CPG files\n",
        "    cpg_root_directory = \"/content/drive/MyDrive/Training_Data_BTP/HINDI-DEPENDENCY-ALL-DOMAINS-LATEST/Data/\"\n",
        "\n",
        "    # Get all CPG files\n",
        "    cpg_files = get_cpg_files_from_directory(cpg_root_directory)\n",
        "\n",
        "    # Paths to UD files\n",
        "    ud_files = [\n",
        "        \"/content/drive/MyDrive/Training_Data_BTP/UD_Hindi-HDTB/hi_hdtb-ud-dev.conllu\",\n",
        "        \"/content/drive/MyDrive/Training_Data_BTP/UD_Hindi-HDTB/hi_hdtb-ud-train.conllu\",\n",
        "        \"/content/drive/MyDrive/Training_Data_BTP/UD_Hindi-HDTB/hi_hdtb-ud-test.conllu\"\n",
        "    ]\n",
        "\n",
        "    # Output path\n",
        "    output_file = \"/content/drive/MyDrive/Training_Data_BTP/parallel_data_exact_match1.txt\"\n",
        "\n",
        "    # Extract and process\n",
        "    sentences = extract_cpg_sentences(cpg_files)\n",
        "    cpg_blocks = parse_cpg_blocks(cpg_files)\n",
        "    ud_blocks = parse_ud_blocks(ud_files)\n",
        "\n",
        "    # Perform exact alignment\n",
        "    align_and_output_exact(sentences, cpg_blocks, ud_blocks, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbIUPRVzTFVx",
        "outputId": "3cce6632-8446-4ab3-d260-057ea5b7c8eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement re (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for re\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
            "\u001b[0mâ†’ Converted to /content/drive/MyDrive/Training_Data_BTP/Training_Data.jsonl\n"
          ]
        }
      ],
      "source": [
        "!pip install re\n",
        "import re\n",
        "import json\n",
        "\n",
        "def convert_parallel_txt_to_jsonl(txt_path, jsonl_path):\n",
        "    \"\"\"\n",
        "    Reads a file where each entry is:\n",
        "      ### Sentence ID: N\n",
        "      ...\n",
        "      ==UD==\n",
        "      [UD lines]\n",
        "      ==CPG==\n",
        "      [CPG lines]\n",
        "\n",
        "    and writes out JSONL where each line is:\n",
        "      { \"input\": \"<all-of-CPG>\", \"target\": \"<all-of-UD>\" }\n",
        "    \"\"\"\n",
        "    with open(txt_path, 'r', encoding='utf-8', errors='replace') as fin, \\\n",
        "         open(jsonl_path, 'w', encoding='utf-8') as fout:\n",
        "        content = fin.read().split(\"### Sentence ID:\")\n",
        "        for block in content:\n",
        "            if not block.strip():\n",
        "                continue\n",
        "            # isolate UD and CPG\n",
        "            ud_match = re.search(r\"==UD==\\n(.+?)\\n==CPG==\", block, re.DOTALL)\n",
        "            cpg_match = re.search(r\"==CPG==\\n(.+?)(?:\\n### Sentence ID:|\\Z)\", block, re.DOTALL)\n",
        "            if not ud_match or not cpg_match:\n",
        "                continue\n",
        "            ud_text  = ud_match.group(1).strip()\n",
        "            cpg_text = cpg_match.group(1).strip()\n",
        "            # JSONL line\n",
        "            j = { \"input\": cpg_text, \"target\": ud_text }\n",
        "            fout.write(json.dumps(j, ensure_ascii=False) + \"\\n\")\n",
        "    print(f\"â†’ Converted to {jsonl_path}\")\n",
        "\n",
        "# Example usage\n",
        "convert_parallel_txt_to_jsonl(\"/content/drive/MyDrive/Training_Data_BTP/parallel_data_exact_match1.txt\", \"/content/drive/MyDrive/Training_Data_BTP/Training_Data.jsonl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgSS4YOXTr07"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
